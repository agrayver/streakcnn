%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\RequirePackage{fix-cm}
%
\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
\usepackage[numbers]{natbib}
\usepackage{hyperref}
\usepackage{color}
\usepackage{ulem}

%for revisions
\newcommand{\new}[1]{\textit{\textcolor{red}{#1}}}
\newcommand{\old}[1]{\textcolor{blue}{\sout{#1}}}

\begin{document}

\title{Particle streak velocimetry using Ensemble Convolutional Neural Networks}
\titlerunning{Streaks imaging with CNN}        % if too long for running head

\author{Alexander V. Grayver         \and
        Jerome Noir
}

\institute{A. V. Grayver \at
              Institute of Geophysics, ETH Zurich \\
              Sonneggstrasse 5 \\
							8092 Zurich, Switzerland \\
              Tel.: +41-44-6333154\\
              \email{agrayver@erdw.ethz.ch}
              \and
           J. Noir \at
					    Institute of Geophysics, ETH Zurich \\
              Sonneggstrasse 5 \\
							8092 Zurich, Switzerland \\
              Tel.: +41-44-6337593\\
              \email{jerome.noir@erdw.ethz.ch}
}

\date{Received: - / Accepted: -}


\maketitle

\begin{abstract}
This study reports an approach and presents its open-source implementation for quantitative analysis of experimental flows using streak images and Convolutional Neural Networks (CNN). The latter are applied to retrieve a length and an angle from streaks, which can be used to deduce kinetic energy and directionality (up to 180$^{\circ}$ ambiguity) of an imaged flow. We developed a quick method for generating essentially unlimited number of training and validation images, which enabled efficient training. Additionally, we show how to apply an ensemble of CNNs to derive a formal uncertainty on the estimated quantities. The approach is validated on the numerical simulation of a convenctive turbulent flow and applied to a longitutidal libration flow experiment.
\keywords{Streak analysis \and Neural Networks \and Turbulent Flows}
\end{abstract}

\section{Introduction}
\label{sec:intro}

Particle Image Velocimetry (PIV) is arguably the most widely used technique to quantitatively study experimental flows \cite{westerweel1997fundamentals, raffel2018particle}. A common work-flow would consist of seeding a flow with luminescent particles and taking pairs of pictures with a known short time separation to capture an instantaneous flow state. By splitting a pair of images into (possibly overlapping) windows and cross-correlating between them allows one to infer the direction and magnitude of the flow. With modern computers and digital cameras, PIV has experienced wide adoption in the academic and industrial domains \cite{tropea2007springer}.
For cross-correlation to work properly, one has to ensure that the exposure time is short enough such that particles do not move more than a few pixels and the two images have clearly identifiable correlations \cite{westerweel1997fundamentals}. Violating this condition, for instance because of an insufficient laser intensity or a too fast flow, results in so called streaks - traces of particles.

Streaks in the PIV images are commonly considered an experimental failure since they render cross-correlation techniques less efficient or even inapplicable. When flow velocity imposes constraints for which the camera and light source at hand cannot capture instantaneous particle positions, one either has to use a higher speed camera or/and a stronger light source. Both of these solutions quickly hit financial and safety constraints, which often cannot be overcome in academia. Therefore, there exists a need for processing techniques.
Although not suitable for conventional cross-correlation methods, streak images do carry information about the flow. \old{Whereas an image with streaks does not contain information about direction of the underlying flow, information on the mean velocity magnitude and azimuth can be inferred from streaks themselves. To the best of authors' knowledge, there are no reliable algorithms to recover quantitative information from streaks images, which motivated us to design a method for extracting information about the flow from streaks.} \new{Indeed, the streaks provide quantitative information on the mean velocity magnitude and azimuth of the displacement of the particles over the exposure time of the photography. The only information lost in a streak image in comparison with a pair of PIV images is the direction of the flow, leading to an ambiguity of $180^{\circ}$, no matter which algorithm will be used to analyze the images. We first considered probabilistic Hough transforms \citep{galamhos1999}, a widely used algorithm in computer vision to detect lines in images. However, this approach requires fine tuning for each different test image and often fails at detecting several streaks leading to an incomplete recovery of the information (see the Jupyter notebook \href{https://github.com/agrayver/streakcnn/blob/master/test_Hough_on_DNS_skimage.ipynb}{HoughAppliedToDNS.ipynb} on our GitHub for an example). To the best of authors' knowledge, there are no other reliable algorithms to recover quantitative information from streaks images, which motivated us to design a method for extracting information about the flow from streaks}

To this end, we applied an ensemble of Convolutional Neural Networks (CNN) trained on streak images to draw a statistical prediction of the displacement magnitude and corresponding azimuth. The potential of CNNs has long been recognized for applications related to the face and handwriting recognition \cite{lawrence1997face, simard2003best}, although their power has been fully discovered only recently when deeper (that is, with more layers) networks became feasible to train within reasonable amount of time, mostly due to the emergence of affordable Graphic Processor Units (GPUs) \cite{krizhevsky2012imagenet, karpathy2014large}. An interested reader is referred to a recent overview of the deep learning with important development milestones listed \cite{lecun2015deep}.

Before we proceed to describ\old{ing}\new{e} methodology and results, it is worth to mention that a crucial ingredient to a success of CNNs is a suitably large training set, which a CNN is supposed to learn from without facing an over-fitting. \old{From this perspective, streak analysis appears almost an ideal problem}\new{Therefore, building a training set from numerical simulation appears disadvantageous for two reasons: (i) producing a set of numerical simulations, which exhaustively covers the anticipated range of parameters is extremely resource demanding if not infeasible and (ii) since our main goal is to study fast turbulent flows, any numerical simulation will be band-limited, thereby lacking information on some wavelengths}. \new{In contrast, and} similar to \new{the} PIV, we make a reasonable assumption that within a sufficiently small interrogation window velocity exhibits \new{a} simple functional form (for instance, constant or linear function). This allows us to quickly generate an unlimited number of \new{window-based} training images. Adding variability in number of streaks per window, their thickness and intensity \old{will} mimic\new{s} a realistic experimental scenario sufficiently well. Therefore, we can exhaustively sample the parameter space and feed the network with as many sample\new{s} as needed to attain an acceptable accuracy. The specific numbers and parameters will be discussed in the corresponding sections below.

\section{Methods}
\label{sec:methodology}

\subsection{Problem setup}

We aim at inferring the displacement and azimuth from a streak image of $N \times N$ pixels, typically as illustrated in Figure \ref{fig:expImage}.

\begin{figure}
	\includegraphics[width=\textwidth]{figs/figure0.jpg}
	\caption{Streaks image ($1024\times1024$ pixels) from a longitudinal libration experiment in a cylindrical cavity. See section \ref{experiment} for details}
	\label{fig:expImage}
\end{figure}
Similarly to how PIV is applied to a pair of images, we split the image into ($n \times n$, with n=48 in this study) sub-windows with an overlap ($50\%$ in our case). Assuming the velocity is sufficiently uniform over the ($n \times n$), we aim at determining the mean length, the displacement over the exposure time, and azimuth for each sub-window. 

A closer look at the image shows that the number of streaks, their intensity and their width, vary within each sub-window. In addition, in many cases, the streaks leave the ($n \times n$) interrogation area. In order to make our CNN resilient to this variability, we generate train and validation images of ($48 \times 48$ pixels) with a random number of streaks varying between 2 and 10, a random color intensity between 90 and 255 and a random thickness between 2 and 4 pixels. The center of each streak is chosen randomly over the entire sub-window, such that streaks are allowed to go outside the image.

To generate train and validation images, we sampled displacement, $\Delta$, and asimuth, $\phi$, from uniform distributions
\begin{equation}
\Delta \sim U(1, \Delta_\textnormal{max}) 
\end{equation}
and
\begin{equation}
\phi \sim U(-\pi/2+\delta, \pi/2),
\end{equation}
respectively. 

Here, $\phi = 0$ corresponds to the positive $x$-axis and increases clockwise. 
Note that limits for $\phi$ cover only half of the circle minus $\delta = 5^{\circ}$ on one end to mitigate ambiguity with respect to the direction. Once streaks are generated, the intensity within each streak intensity is perturbed and the image is blurred with a Gaussian kernel of $3\times 3$ pixels. In this study, the maximum displacement, $\Delta_\textnormal{max}$, of a particle within an image is assumed to be half of the chosen window size, that is $r_\textnormal{max} = 24$ pixels. 

Figure \ref{fig:fig1} shows a selection of streak images generated using the stated procedure. The outlined procedure enables generation of millions of images in just a few minutes on a regular PC. 

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure1.png}
\caption{Subset of generated streak images used for training and validation with the corresponding displacements (in pixels) and azimuth angles (in degrees) given in the titles.}
\label{fig:fig1}
\end{figure}

\subsection{Network architecture and implementation}

We aim at building a regression CNN that, given a single window image, outputs two real numbers, corresponding to the displacement and angle. To this end, we have created a network with the architecture shown in Figure \ref{fig:figcnn}. As can be seen, four convolutional units form the core of the network, each consisting of a convolutional layer, activation layer (in this case, rectified linear unit), average pooling layer used to downsample the input followed by a batch normalization layer. An increasing depth of the convolutional layers is a common choice aimed at giving a network ability to learn more complex features from the input. 

To prevent overfitting and improve training speed, we used batch normalization at the end of each convolution unit \cite{ioffe2015batch} and a dropout layer with the 30\% drop fraction \cite{srivastava2014dropout}. Additionally, following common practices, the outputs are standartized and centered. The input grayscale images have a single eight bits channel and are normalized by 255 to stay in the $[0, 1]$ range.

Whereas there may exist more efficient architectures, we found that for our problem increasing depth of the network has not improved overall performance significantly, nor did increasing and/or decreasing filter sizes. Additionally, we found that, in contrast to majority of the reported CNN architectures, using the average pooling instead of the max pooling results in a slightly higher accuracy.

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure_CNN.png}
\caption{Architecture of the used network. Left: sequence of layers and corresponding parameters in the brackets. Each CUNIT layer consists of four actual layers listed in the middle column. Relevant layer parameters are given on the right. Total number of learnable parameters in the network is 44370.}
\label{fig:figcnn}
\end{figure}

To increase accuracy and robustness of the prediction, we built an ensemble consisting of ten networks \cite{hinton2015distilling}. All networks have the same architecture and parameters, but were trained using different randomly chosen initial weights \cite{glorot2010understanding, he2015delving} and random shuffling to form a unique sequence of batches supplied to an optimizer. The outputs of all ensemble members are averaged to get a the final prediction and its variance, thereby providing a proxy for the uncertainty of a prediction.

Finally, the network was implemented using the PyTorch library \cite{paszke2017automatic}. The complete implementation can be found in GitHub using the link below.

\section{Results}

\subsection{Network training}

We generated one million images (e.g., Figure \ref{fig:fig1}) of which 75\% and 25\% were used for training and validation, respectively. Each network in the ensemble has been trained for 100 epochs. The ADAM optimizer with an initial learning rate value of 1e-3 was used. The learning rate was halved if no sufficient decrease in the validation loss was observed for the past 10 epochs. To make the training more resistant to potential outliers (e.g. imagine a situation when all streaks leave the window), we chose to minimize the Huber loss \cite{huber1973robust} rather than conventional least-squares loss. Huber loss represent a hybrid $L_2-L_1$ distribution with a high tolerance to the presence of long tails in the original distribution. 
No pathologies between training and validation losses were observed during the training, specifically the validation loss remained a bit higher than the training loss, indicating that the network learns some generic features of the dataset. Training of each network took $\approx 90$ minutes on a single CPU-GPU system. \old{This modest time suggests that training networks for window sizes larger that the one adopted here is feasible.}\new{The modest training time ensures feasibility of training networks for window sizes larger that $48 \times 48$ pixels adopted here.}

Figure \ref{fig:fig3} shows RMSE values for all networks seperately as well as the RMSE of the ensemble. \new{RMSE was calculated as} 
\begin{equation}
\textnormal{RMSE} = \sqrt{\frac{1}{N}\sum_{i = 1}^N{\left(\frac{x_i - \tilde{x}_i}{\tilde{x}_i}\right)^2}}
\end{equation}
\new{where $\tilde{x}$ and $x$ are the true and predicted values, respectively, of $\Delta$ or $\phi$.}

It is evident that the ensemble performs up to ~20\% better than a single network. CNN ensemble achieves the accuracy of 1.05 pixels for the displacement and $8.5^{\circ}$ for the angle predictions, respectively. The latter may seem like a large error, however one should realize that having a $48 \times 48$ pixels window inevitably leads to limitations in recognizing small rotations, especially when streaks are short. 

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure2a.png}
\includegraphics[width=\textwidth]{figs/figure2b.png}
\caption{Top: RMSE values of individual networks (markers) and ensemble (line) for displacement $\Delta$ and angle $\phi$ calculated on the validation set. Bottom: histograms of the residuals for the displacement and angle. \new{Histograms for both absolute and relative (i.e., normalized by the true displacement) residuals are shown.JN>>>WHY IS RMSE STILL IN PIXELS, FROM (3) IT SHOULD BE DIMENSIONLESS}}
\label{fig:fig3}
\end{figure}

Figure \ref{fig:fig4} shows a random selection of validation images with the corresponding ensemble CNN predictions and true values. We see that the ensemble CNN has learned to make accurate prediction even for complex situations when some streaks overlap, join or leave the window. \new{For instance, in Figure \ref{fig:fig4}(bottom row, middle), two streaks coincidenta\new{l}ly joined and formed what appears to be a longer streak, but CNN prediction is not confused since other streaks provide enough information for an accurate prediction.} Additionally, Figure \ref{fig:fig5} shows nine images which produced the worst predictions of the displacement. Clearly, most of these cases are associated with situations where originally longer streaks have all been displaced outside the window\old{ or multiple streaks coincidenta\new{l}ly joined and formed what appears to be a longer streak}. Note that such situations do not represent a failure of the CNN, but rather limitation of the window-based approach adopted in this work. Similar situations are likely to occur in experimental images and ufortunately they leave little chance for any sliding window approach to make an accurate prediction. We will discuss possible ways to mitigate this in the Conclusions section. It is worth to note that despite inaccurate displacement prediction, the angle is predicted accurately in most of these cases. 

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure3.png}
\caption{Images with the predicted displacement and angle depicted as magenta lines. The true values are given in titles and predicted values in brackets.}
\label{fig:fig4}
\end{figure}

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure4.png}
\caption{Same as previous, but showing nine worst prediction in terms of displacement.}
\label{fig:fig5}
\end{figure}

\subsection{\old{Application} \new{Validation using synthetic flows from numerical simulations}.}

After confirming the excellent performance of the network on the validation set, we turn to a discrete numerical simulation (3D-DNS) of a complex thermal convection turbulent flow presented recently by \cite{plumley2016effects}. In their paper, the authors simulate rapidly rotating thermal convection in a square box, heated from below and cooled from the top with a vertical gravitational field pointing downward and a vertical axis of rotation. To validate our CNN algorithm, we used a simulation obtained for $E=10^{-7}$, where $E$ is the Ekman number representing the ratio of viscous to rotational effect, and a Raleigh number that is 90 times supercritical. Each velocity field is $192^3$. For the purpose of this study, we extracted the horizontal component of the velocity in a horizontal plane a mid-depth. Due to the limited size of the calculation each velocity component has been interpolate on a $1024\times 1024$ pixels grid. 
Figure \ref{fig:fig6}-left shows the displacement map obtained from the full DNS for an arbitrary exposure time. Since the CNN will act on ($48\times48$) interrogation windows with the $50\%$ overlap, we apply a sliding window averaging with ($48\times48$) and $50\%$ overlap (Figure \ref{fig:fig6}-right). The window averaged displacement is the best reconstruction we can possibly achieve with a $48 \times 48$ pixels window and a 50\% overlap used in this study, thus all later results will be compared against it.

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure5.png}
\caption{Original (left) and window averaged (right) displacement maps of the DNS \cite{plumley2016effects} used for validation. \new{The arrows on the left shows the true horizontal vector field from the DNS.}}
\label{fig:fig6}
\end{figure}

To reduce subjectivity, we generated 30 randomly seeded streak images using the original DNS velocity (Figure \ref{fig:fig6}, left) \old{and varying streak density, intensity and thickness as formerly stated}. \new{We first split the image into $48\times48$ pixels subwindows, inside which we calculate the mean linear displacement $\vec{d}=\vec{\bar{u}}dt$, where $\vec{\bar{u}}$ represents the horizontal velocity average over $48\times48$ pixels. In each subwindow we generate a random seeding, varying the density (from 1 to 10 seeds per subwindow) and radius (from 2 to 4 pixels) of the seeds and reconstruct the associated streaks. Finally we apply a Gaussian filter with a kernel of 1 pixel to mimic the natural variability of intensity observed in experimental images. We repeat the entire process to generate 30 independent streak images from the same velocity field. }
The trained CNN ensemble was applied to all images and the resulting averaged reconstruction of both displacement and angle are shown in Figure \ref{fig:fig7}. We see that the reconstructed images recover the general structure of the flow very well. The only undesired effect is that the ensemble CNN struggles to correctly predict large displacements. When the displacement reaches half of the window size, CNN systematically predicts smaller displacements. The reason for this is not a deficiency of the CNN, but rather the fact that for displacements as large as half the window size it becomes very likely that most of the streaks go outside the window, thus a smaller displacement is a rational prediction. To solve this problem, one could apply a larger window (for instance, $64\times 64$ pixels), although this will reduce the overall resolution and may render constant velocity assumption less accurate. In real experimental settings, it may be advantageous to apply several window sizes and either choose one or combine obtained results, depending on a particular experimental setup.

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure6.png}
\caption{Original (left) and window averaged (right) displacement maps of the DNS \cite{plumley2016effects} used for validation.}
\label{fig:fig7}
\end{figure}

Finally, Figure \ref{fig:fig8} shows one of the streak images generated from DNS with the true and predicted streaks for each window position. Note that while the whole velocity field is used to generate the background streak images, the overlying red streaks are reconstructed at the location of the CNN grid point using the averaged displacement and angle maps (Figure \ref{fig:fig6}). Generally, ensemble CNN performs well. There is, however, accuracy reduction in regions of large displacements for reasons described above and across areas of vertical shearing, where angle predictions become locally less accurate. Interestingly, these vertical shear regions also lead to abnormal streaks orientation (close to horizontal) when using the window averaged field values (red streak in Figure \ref{fig:fig6}).

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure7.png}
\caption{Streak image generated from the DNS with true and predicted displacement and angle shown as red and yellow lines, respectively.}
\label{fig:fig8}
\end{figure}

\subsection{Application to the flow driven by longitudinal libration in laboratory experiment}\label{experiment}
Finally, we apply our algorithm to a laboratory experiment depicted in figure \ref{fig:MeisterMSC}. The apparatus consists of a straight cylinder filled with water set in rotation on a turntable at 1Hz. The cavity is 286mm high with a radius of 140mm. The bottom lead is covered with topography made of blocks ($64mm\times64mm\times 8mm$). A second motor is used to oscillate the container on the turntable, resulting in the so-called longitudinal libration.
\old{For the purpose of this experimental validation we have set the libration frequency to 1 Hz and the amplitude to $34^{\circ}$} \new{In such a system, flows at low libration amplitudes are in the form of linear inertial waves and inertial modes, as the amplitude increases the flows become unstable and eventually saturate with a significant geostrophic component, i.e. mainly two dimensional. For the purpose of this experimental validation we have set the libration frequency to 1Hz and the amplitude to $34^{\circ}$, which corresponds to the geostrophic saturation state aforementioned. }

To obtain the streak images, we use a 1W continuous diode laser to illuminate a horizontal plane of the fluid seeded with fluorescent particles. We record movies of the particles motion at a fixed exposure time of 21ms with a sampling frequency of 30 images per second. We extracted a frame corresponding to a maximum apparent amplitude of the swirling flow (\ref{fig:expImage}).
     
\begin{figure}
	\includegraphics[width=\textwidth]{figs/figureExperiment.jpg}
	\caption{Experimental setup of the longitudinal libration experiment \cite{MeisterMSC}.}
	\label{fig:MeisterMSC}
\end{figure}

A pre-processing step was necessary for real images to filter out the CCD matrix noise. We achieved this by a simple shareholding of an image at intensity of 50. After that, image was split into overlapping $48\times 48$ pixels windows, resulting in a total of 2400 window images. The ensemble CNN was then applied to predict displacements and angles as well as their standard deviations with the latter serving to be a proxy for the output uncertainties. 

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure8a.png}
\caption{Predicted displacement and angle (left) along with their standard deviations (right) inferred from the ensemble CNN for an experimental image shown in Figure \ref{fig:fig10}.}
\label{fig:fig9a}
\end{figure}

Figures \ref{fig:fig9a}-\ref{fig:fig9b} show the predictions \old{in the form of maps and histograms, respectively}\new{ of the displacement and azimuth in the form of maps and histograms for one randomly chosen frame of the movie}. Figure \ref{fig:fig10} shows the \old{actual} \new{selected} experimental image we used and window-centered predictions drawn as lines. First of all, we see that experimental flow exhibits rather involved behaviour, with regions where streaks show non-linear behvaiour of the flow within a window, which violates our initial assumptions. Nonetheless, the ensemble CNN produces coherent and spatially correlated predictions (Figure \ref{fig:fig9a}). It is also interesting to analyse the standard deviation maps (Figure \ref{fig:fig9b}). Large absolute errors in the displacement map appear to be correlated with regions of fast flow. On the other hand, large uncertainties in the angle occur around regions with vertical velocity shear, as observed in DNS synthetic images, specifically where velocity seems to flip the direction.

\new{Finally, we applied the CNN ensemble to the entire movie and calculated the mean kinetic energy from the displacement for each frame. Subsequently, Power Spectral Density of the time-series was calculated (Figure \ref{fig:fig10}). As anticipated, we can clearly identify the forcing frequency at 1Hz and the harmonics at 2 and 3Hz resulting from non-linear effects.} 

\begin{figure}
\includegraphics[width=\textwidth/2]{figs/figure8b.png}
\caption{Same as above, but in a form of histograms.}
\label{fig:fig9b}
\end{figure}

In terms of performance, ensemble CNN attains a speed of seven full images (each totaling to 2400 windows) per second on an NVIDIA GoForce GTX 1070Ti powered PC. This level of performance allows us to comfortably process long sequences of images taken during experiment, which we use to study evolution of the kinetic energy. Using a more modern GPU will likely also enable real-time predictions at rates of a few dozens of images per second, which could be more relevant for industrial applications.

\begin{figure}
\includegraphics[width=\textwidth]{figs/figure9.png}
\caption{Streak image taken during an experiment overlain by the predicted displacement and angle shown as red lines.}
\label{fig:fig10}
\end{figure}


\begin{figure}
	\includegraphics[width=\textwidth]{figs/figure10.png}
	\caption{\new{Left: Mean kinetic energy calculated from the displacement in each frame of the movie. Right: Normalized power spectral density of the mean kinetic energy.}}
	\label{fig:fig10}
\end{figure}


\section{Conclusions}

We presented an open-source ensemble CNN aimed at quantitative analysis of complex experimental flows using streak images. The presented approach can be applied in situations when classical PIV is inaccurate or not possible due to experimental setup or hardware limitations. The advantage of the presented approach is the ease of training/validation set generation as well as recovery of the prediction uncertainty through application of the ensemble method. We foresee that the approach may need an experiment-dependent tailoring to achieve the best performance. According to our experience, this only takes a single day on an average PC equipped with a modern GPU and should not represent a practical limitation.

The potential extensions of the presented approach may include the use of multiple window sizes applied to the same image, more complex functional parameterizations of the displacement and angle fields within a window (e.g., polynomial). Finally, a completely different approach based on an image segmentation and object localization and/or tracking can be applied to extract information about individual streaks and their evolution in time. We expect to investigate these directions in details in our future studies.

\begin{acknowledgements}
We thank authors of PyTorch, mathplotlib and h5py libraries for making them available, Meredith Plumley for sharing her DNS data, Adrian Tasistro-Hart for a number of insightful discussions on CNNs. \new{Comments by two anonymous reviewers helped improve the manuscript.} The Jupyter Python notebooks of all programs used in this study can be found here \url{https://github.com/agrayver/streakcnn}.
\end{acknowledgements}

% References
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{refs}

% Non-BibTeX users please use
\begin{thebibliography}{17}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem{galamhos1999}
Galamhos, C., Matas, J. and Kittler, J.: Progressive probabilistic Hough transform for line detection.
\newblock Proceedings. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 554--560 (1999)

\bibitem{glorot2010understanding}
Glorot, X., Bengio, Y.: Understanding the difficulty of training deep
  feedforward neural networks.
\newblock In: Proceedings of the thirteenth international conference on
  artificial intelligence and statistics, pp. 249--256 (2010)

\bibitem{he2015delving}
He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectifiers: Surpassing
  human-level performance on imagenet classification.
\newblock In: Proceedings of the IEEE international conference on computer
  vision, pp. 1026--1034 (2015)

\bibitem{hinton2015distilling}
Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural
  network.
\newblock arXiv preprint arXiv:1503.02531  (2015)

\bibitem{huber1973robust}
Huber, P.J., et~al.: Robust regression: asymptotics, conjectures and monte
  carlo.
\newblock The Annals of Statistics \textbf{1}(5), 799--821 (1973)

\bibitem{ioffe2015batch}
Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training
  by reducing internal covariate shift.
\newblock arXiv preprint arXiv:1502.03167  (2015)

\bibitem{karpathy2014large}
Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.:
  Large-scale video classification with convolutional neural networks.
\newblock In: Proceedings of the IEEE conference on Computer Vision and Pattern
  Recognition, pp. 1725--1732 (2014)

\bibitem{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep
  convolutional neural networks.
\newblock In: Advances in neural information processing systems, pp. 1097--1105
  (2012)

\bibitem{lawrence1997face}
Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D.: Face recognition: {A}
  convolutional neural-network approach.
\newblock IEEE transactions on neural networks \textbf{8}(1), 98--113 (1997)

\bibitem{lecun2015deep}
LeCun, Y., Bengio, Y., Hinton, G.: Deep learning.
\newblock nature \textbf{521}(7553), 436 (2015)

\bibitem{MeisterMSC}
Meister, A.: Effects of boundary topography on the flow forced by libration in
  longitude in a rotating cylinder, master thesis, ethz, (2018)

\bibitem{paszke2017automatic}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in
  {P}y{T}orch.
\newblock In: NIPS-W (2017)

\bibitem{plumley2016effects}
Plumley, M., Julien, K., Marti, P., Stellmach, S.: The effects of {E}kman
  pumping on quasi-geostrophic {R}ayleigh--{B}{\'e}nard convection.
\newblock Journal of Fluid Mechanics \textbf{803}, 51--71 (2016)

\bibitem{raffel2018particle}
Raffel, M., Willert, C.E., Scarano, F., K{\"a}hler, C.J., Wereley, S.T.,
  Kompenhans, J.: Particle image velocimetry: a practical guide.
\newblock Springer (2018)

\bibitem{simard2003best}
Simard, P.Y., Steinkraus, D., Platt, J.C., et~al.: Best practices for
  convolutional neural networks applied to visual document analysis.
\newblock In: Icdar, vol.~3 (2003)

\bibitem{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.:
  Dropout: a simple way to prevent neural networks from overfitting.
\newblock The Journal of Machine Learning Research \textbf{15}(1), 1929--1958
  (2014)

\bibitem{tropea2007springer}
Tropea, C., Yarin, A.L.: Springer handbook of experimental fluid mechanics.
\newblock Springer Science \& Business Media (2007)

\bibitem{westerweel1997fundamentals}
Westerweel, J.: Fundamentals of digital particle image velocimetry.
\newblock Measurement science and technology \textbf{8}(12), 1379 (1997)

\end{thebibliography}

\end{document}
